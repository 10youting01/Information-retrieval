{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import log10\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_path = \"data\"\n",
    "dic = []\n",
    "# Put all the document in the same list\n",
    "for sub in os.listdir(par_path):\n",
    "    file_path = os.path.join(par_path, sub)\n",
    "    if os.path.isfile(file_path) and sub.endswith(\".txt\"):\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            dic.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate every words in each documents \n",
    "sep_dic = []\n",
    "for content in dic:\n",
    "    content = content.split()\n",
    "    sep_dic.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~` '''\n",
    "punc_dic = []\n",
    "for con in sep_dic:\n",
    "    new_con = []\n",
    "    for term in con:\n",
    "        new_t = term.replace('!', '').replace('(', '').replace(')', '').replace('-', '').replace('[', '').replace(']', '').replace('{', '').replace('}', '').replace(';', '').replace(':', '').replace('\"', '').replace('\\'', '').replace(',', '').replace('<', '').replace('>', '').replace('.', '').replace('/', '').replace('?', '').replace('@', '').replace('#', '').replace('$', '').replace('%', '').replace('^', '').replace('&', '').replace('*', '').replace('*', '').replace('_', '').replace('~', '').replace('`', '').replace(' ', '')\n",
    "        new_con.append(new_t)\n",
    "    punc_dic.append(new_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~` '''\n",
    "punc_dic = []\n",
    "for con in sep_dic:\n",
    "    new_con = []\n",
    "    for term in con:\n",
    "        for ele in punc:\n",
    "            new_t = term.replace(ele, '')\n",
    "            new_con.append(new_t)\n",
    "    punc_dic.append(new_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numeric and null term\n",
    "oth_dic = []\n",
    "for con in punc_dic:\n",
    "    temp_con = []\n",
    "    for term in con:\n",
    "        if any(char.isnumeric() for char in term):\n",
    "            continue\n",
    "        if len(term) > 0:\n",
    "            temp_con.append(term)\n",
    "    oth_dic.append(temp_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dic = []\n",
    "for con in oth_dic:\n",
    "    temp_con = []\n",
    "    for term in con:\n",
    "        term = term.lower()\n",
    "        temp_con.append(term)\n",
    "    low_dic.append(temp_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming using Porter's algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_dic = []\n",
    "for con in low_dic:\n",
    "    temp_con = []\n",
    "    for term in con:\n",
    "        new_t = ps.stem(term)\n",
    "        temp_con.append(new_t)\n",
    "    stem_dic.append(temp_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as st:\n",
    "    stopword = list(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [words.split() for words in stopword]\n",
    "# put every stopword in different list into the same list\n",
    "stopwords = sum(stopwords, []) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_dic = []\n",
    "for con in stem_dic:\n",
    "    temp_con = []\n",
    "    for term in con:\n",
    "        if term not in stopwords or term.isnumeric() or len(term) == 0:\n",
    "            temp_con.append(term)\n",
    "    stop_dic.append(temp_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = []\n",
    "for con in stop_dic:\n",
    "    temp = {}\n",
    "    for term in con:\n",
    "        if term not in temp:\n",
    "            temp[term] = 1\n",
    "        else:\n",
    "            temp[term] = temp[term] + 1\n",
    "    tf.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = []\n",
    "for con in stop_dic:\n",
    "    for term in con:\n",
    "        if term not in dic:\n",
    "            dic.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/dictionary.txt\", \"w\") as output_file:\n",
    "    for content in dic:\n",
    "        output_file.write(content+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for term in dic:\n",
    "    df[term] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in dic:\n",
    "    for con in stop_dic:\n",
    "        if term in con:\n",
    "            df[term] = df[term] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "N = 1095\n",
    "for term in dic:\n",
    "    df_term = df[term]\n",
    "    idf[term] = math.log10(N/df_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "for con in stop_dic:\n",
    "    doc = {}\n",
    "    for term in con:\n",
    "        doc[dic.index(term)] = tf[stop_dic.index(con)][term] * idf[term]\n",
    "    tfidf.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = []\n",
    "for doc in tfidf:\n",
    "    temp = 0\n",
    "    for term in doc.items():\n",
    "        temp += 1\n",
    "    item.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 0\n",
    "for doc in tfidf:\n",
    "    doc_id += 1\n",
    "    with open(f\"output/{doc_id}.txt\", \"w\") as output_file:\n",
    "        output_file.write(str(item[doc_id-1]) + \"\\n\")\n",
    "        for term_idx, tfidf_s in doc.items():\n",
    "            output_file.write(f\"{term_idx}: {tfidf_s}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = tfidf[0]\n",
    "doc2 = tfidf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(doc_vec1, doc_vec2):\n",
    "    dot_product = sum(doc1[term] * doc2[term] for term in doc1 if term in doc2)\n",
    "    \n",
    "    magnitude1 = math.sqrt(sum(doc1[term] ** 2 for term in doc1))\n",
    "    magnitude2 = math.sqrt(sum(doc2[term] ** 2 for term in doc2))\n",
    "    \n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = dot_product / (magnitude1 * magnitude2)\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2712112524896092\n"
     ]
    }
   ],
   "source": [
    "sim12 = cosine_similarity(doc1, doc2)\n",
    "print(sim12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
